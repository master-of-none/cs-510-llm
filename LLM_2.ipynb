{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZJD3b8ITb9lRtRNp9MTHn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/master-of-none/cs-510-llm/blob/main/LLM_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2JdLse_jqiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0a8863-07d9-4620-cb3b-174a12318fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\n",
        "\n",
        "# Load text classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"bigscience/bloom-560m\", tokenizer=tokenizer)\n",
        "\n",
        "# Open the input file and read the first 20 lines\n",
        "texts = []\n",
        "with open(\"test.jsonl\", \"r\", encoding=\"utf-8\") as file:\n",
        "    for i, line in enumerate(file):\n",
        "        if i >= 100  # Process only the first 20 lines\n",
        "            break\n",
        "        data = json.loads(line)\n",
        "        texts.append(data[\"text\"])\n",
        "\n",
        "# Define candidate labels\n",
        "candidate_labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Open a new file to save the results\n",
        "with open(\"results.jsonl\", \"w\", encoding=\"utf-8\") as results_file:\n",
        "    # Classify text inputs using zero-shot approach\n",
        "    for text in texts:\n",
        "        result = classifier(text, candidate_labels)\n",
        "        predicted_label = result[\"labels\"][0]\n",
        "        predicted_score = result[\"scores\"][0]\n",
        "        # Write the results to the file\n",
        "        results_file.write(json.dumps({\"text\": text, \"predicted_sentiment\": predicted_label, \"confidence_score\": predicted_score}) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sjuwkcOujrKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}